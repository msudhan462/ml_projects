{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM0JjnMXz5u7W+4nhOAmzxu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"QrjtsKgHbWEW","executionInfo":{"status":"ok","timestamp":1687607857052,"user_tz":-330,"elapsed":6756,"user":{"displayName":"Madhusudhana","userId":"07612415316378441544"}}},"outputs":[],"source":["import tensorflow as tf"]},{"cell_type":"code","source":["url = \"https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\"\n","shakespear_raw_text = tf.keras.utils.get_file(fname=\"shakespeare.txt\", origin=\"https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\")"],"metadata":{"id":"D4l_G050ba_-","executionInfo":{"status":"ok","timestamp":1687607857053,"user_tz":-330,"elapsed":33,"user":{"displayName":"Madhusudhana","userId":"07612415316378441544"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b56686fe-5f3a-438a-bab7-208fdccfba8f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n","1115394/1115394 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"code","source":["shakespear_raw_text"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"P1HA3VAHbtvW","executionInfo":{"status":"ok","timestamp":1687607857053,"user_tz":-330,"elapsed":15,"user":{"displayName":"Madhusudhana","userId":"07612415316378441544"}},"outputId":"8546d107-7601-437f-e7d4-b7eef272f39a"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/root/.keras/datasets/shakespeare.txt'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["text = \"\"\n","with open(shakespear_raw_text,\"rb\") as read_obj:\n","    # print(read_obj.read().decode(encoding='utf-8')[:1000])\n","    text = read_obj.read().decode(encoding='utf-8')\n","print(text[:10])\n","\n","text = text[:1000]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tOXO2LPEbvbv","executionInfo":{"status":"ok","timestamp":1687607857053,"user_tz":-330,"elapsed":13,"user":{"displayName":"Madhusudhana","userId":"07612415316378441544"}},"outputId":"039524fe-c24e-4779-be4d-750a7ad0c510"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["First Citi\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"o_AkByAxheeC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vocabs = sorted(set(text))\n","print(f\"Vocabs = {vocabs}\")\n","print(f\"Len of Vocab = {len(vocabs)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F1mQak0reKpJ","executionInfo":{"status":"ok","timestamp":1687600679038,"user_tz":-330,"elapsed":47,"user":{"displayName":"Madhusudhana","userId":"07612415316378441544"}},"outputId":"6f5915ad-a170-4785-ae8f-0a764646e884"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Vocabs = ['\\n', ' ', '!', \"'\", ',', '.', ':', ';', '?', 'A', 'B', 'C', 'F', 'I', 'L', 'M', 'N', 'O', 'R', 'S', 'W', 'Y', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'y', 'z']\n","Len of Vocab = 46\n"]}]},{"cell_type":"markdown","source":["Preprocess Text"],"metadata":{"id":"DVHLZt5fc2hQ"}},{"cell_type":"code","source":["ids_from_chars = tf.keras.layers.StringLookup(vocabulary=list(vocabs), mask_token=None)\n","chars_from_ids = tf.keras.layers.StringLookup(vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)\n","def text_preprocessing(data, reverse=False, axis=True):\n","\n","    if reverse:\n","        # numbers to chars\n","        chars = chars_from_ids(data)\n","        # chars join to make sentence\n","        if not axis:\n","            return tf.strings.reduce_join(chars).numpy()\n","        else:\n","            return tf.strings.reduce_join(chars, axis=-1).numpy()\n","    else:\n","        # splitting\n","        data = tf.strings.unicode_split(data, \"UTF-8\")\n","        # converting char to numbers\n","        return ids_from_chars(data)"],"metadata":{"id":"S6n1wq2qdXgA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["all_ids = text_preprocessing(text)"],"metadata":{"id":"YFtH3ef_g_vZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"],"metadata":{"id":"ICfu9GJN_Dxm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for id in ids_dataset.take(10):\n","    char = text_preprocessing(id,reverse=True, axis=False)\n","    print(char.decode(\"UTF-8\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bembxhNu_8n1","executionInfo":{"status":"ok","timestamp":1687600679039,"user_tz":-330,"elapsed":32,"user":{"displayName":"Madhusudhana","userId":"07612415316378441544"}},"outputId":"046eee8c-5381-4ae4-98c2-ce9fc2814410"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["F\n","i\n","r\n","s\n","t\n"," \n","C\n","i\n","t\n","i\n"]}]},{"cell_type":"code","source":["batch=100\n","from pprint import pprint\n","batches = ids_dataset.batch(batch+1, drop_remainder=True)\n","print(pprint(batches.__dict__))\n","for ids in batches.take(1):\n","    chars = text_preprocessing(ids, reverse=True)\n","    # print(chars)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rxo-p_SY_-TZ","executionInfo":{"status":"ok","timestamp":1687600679912,"user_tz":-330,"elapsed":881,"user":{"displayName":"Madhusudhana","userId":"07612415316378441544"}},"outputId":"a771061b-f218-4486-ba9c-85f390a887be"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'_batch_size': <tf.Tensor: shape=(), dtype=int64, numpy=101>,\n"," '_drop_remainder': <tf.Tensor: shape=(), dtype=bool, numpy=True>,\n"," '_graph_attr': <tensorflow.python.framework.ops.Graph object at 0x7f1516cf1960>,\n"," '_input_dataset': <_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int64, name=None)>,\n"," '_name': None,\n"," '_options_attr': <tensorflow.python.data.ops.options.Options object at 0x7f1505951240>,\n"," '_structure': TensorSpec(shape=(101,), dtype=tf.int64, name=None),\n"," '_variant_tensor_attr': <tf.Tensor: shape=(), dtype=variant, value=<BatchDatasetV2Op(101)::Dataset>>}\n","None\n"]}]},{"cell_type":"code","source":["def get_target_label(data):\n","    input = data[:-1]\n","    label = data[1:]\n","    print(input, label)\n","    return input, label\n","\n","print(get_target_label(b\"Madhusudhan reddy\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oC5JEyCPBCZo","executionInfo":{"status":"ok","timestamp":1687600679912,"user_tz":-330,"elapsed":121,"user":{"displayName":"Madhusudhana","userId":"07612415316378441544"}},"outputId":"aa66c617-d794-4fd0-a6a3-27412a3723b9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["b'Madhusudhan redd' b'adhusudhan reddy'\n","(b'Madhusudhan redd', b'adhusudhan reddy')\n"]}]},{"cell_type":"code","source":["dataset = batches.map(get_target_label)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qesa4HL4FdlC","executionInfo":{"status":"ok","timestamp":1687600679913,"user_tz":-330,"elapsed":112,"user":{"displayName":"Madhusudhana","userId":"07612415316378441544"}},"outputId":"9434bae0-2f98-4979-84bb-1f42924f20ca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tensor(\"strided_slice:0\", shape=(100,), dtype=int64) Tensor(\"strided_slice_1:0\", shape=(100,), dtype=int64)\n"]}]},{"cell_type":"code","source":["for d in dataset.take(1):\n","    print(\"Input = \",text_preprocessing(d[0], reverse=True))\n","    print(\"Label = \",text_preprocessing(d[1], reverse=True))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PaexRQvmF1mr","executionInfo":{"status":"ok","timestamp":1687600679913,"user_tz":-330,"elapsed":104,"user":{"displayName":"Madhusudhana","userId":"07612415316378441544"}},"outputId":"c3dc8bfc-86dd-4718-c98f-b88ff4a9097f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input =  b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n","Label =  b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"]}]},{"cell_type":"code","source":["# Batch size\n","BATCH_SIZE = 64\n","\n","# Buffer size to shuffle the dataset\n","# (TF data is designed to work with possibly infinite sequences,\n","# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n","# it maintains a buffer in which it shuffles elements).\n","BUFFER_SIZE = 10000\n","\n","dataset = (\n","    dataset\n","    .shuffle(BUFFER_SIZE)\n","    .batch(BATCH_SIZE, drop_remainder=True)\n","    .prefetch(tf.data.experimental.AUTOTUNE))\n","\n","dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"68JIEi73GMPL","executionInfo":{"status":"ok","timestamp":1687600679913,"user_tz":-330,"elapsed":93,"user":{"displayName":"Madhusudhana","userId":"07612415316378441544"}},"outputId":"9e898344-1ebd-4dd3-9368-c0d44d2c656e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"]},"metadata":{},"execution_count":67}]},{"cell_type":"code","source":["# Models\n","\n","vocab_size = len(ids_from_chars.get_vocabulary())\n","embedding_dim =64\n","rnn_units = 1024\n","\n","\n","class MyModel(tf.keras.Model):\n","    def __init__(self, vocab_size, embedding_dim, rnn_units):\n","        super().__init__(self)\n","        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","        self.gru = tf.keras.layers.GRU(\n","            rnn_units,\n","            return_sequences=True,\n","            return_state = True,\n","        )\n","        self.dense = tf.keras.layers.Dense(vocab_size)\n","\n","    def call(self, inputs, states=None, return_state=False, training=False):\n","        x = inputs\n","        # print(\"Before Prediction = \",text_preprocessing(x,reverse=True))\n","        x = self.embedding(x, training=training)\n","        # print(\"embeddings \",x)\n","        if states is None:\n","            states = self.gru.get_initial_state(x)\n","            # print(\"states \",states)\n","        x, states = self.gru(x, initial_state=states, training=training)\n","        x = self.dense(x, training=training)\n","        # print(\"After prediction = \",text_preprocessing(x,reverse=True))\n","        # print(\"final \",x)\n","        if return_state:\n","            return x, states\n","        else:\n","            return x"],"metadata":{"id":"VtifjBwjG2P4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = MyModel(vocab_size=vocab_size,embedding_dim=embedding_dim,rnn_units=rnn_units)"],"metadata":{"id":"CcyJD6uqIOI0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for input_example_batch, target_example_batch in dataset.take(1):\n","    print(f\"input_example_batch= {input_example_batch}\")\n","    example_batch_predictions = model(input_example_batch, )\n","    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n","    print(f\"example_batch_predictions= {example_batch_predictions}\")"],"metadata":{"id":"zucm9tOVL8c2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# model.summary()"],"metadata":{"id":"1X5fNf81MAGV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sample_indeces = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n","sample_indeces = tf.squeeze(sample_indeces, axis=-1).numpy()\n","print(text_preprocessing(input_example_batch[0], reverse=True))\n","print(text_preprocessing(sample_indeces, reverse=True))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LFhhStc4MiyV","executionInfo":{"status":"ok","timestamp":1687600679914,"user_tz":-330,"elapsed":75,"user":{"displayName":"Madhusudhana","userId":"07612415316378441544"}},"outputId":"9edebe28-bc30-4842-abec-d9336c25c0d8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["b's[UNK]v [UNK][UNK]w [UNK]w[UNK][UNK]C\\nf[UNK] [UNK]sv [UNK]w .[UNK]us[UNK]wv: [UNK]w[UNK][UNK][UNK][UNK][UNK][UNK] [UNK]w [UNK][UNK][UNK][UNK][UNK]v [UNK]s[UNK]w [UNK]ws[UNK]v\\nk[UNK]w [UNK]s[UNK][UNK][UNK] [UNK][UNK]v[UNK][UNK]z[UNK] [UNK]y [UNK][UNK][UNK] z[UNK][UNK]v w[UNK]us[UNK]w?'\n","b\"[UNK];jb[UNK]njd[UNK]N[UNK]'![UNK]zOmdjRe;Iop[UNK][UNK]om[UNK]pjnk[UNK]M:[UNK][UNK].p[UNK][UNK][UNK]mcck[UNK]aflz.[UNK][UNK]Bnbw[UNK][UNK]oMRd[UNK]j[UNK],Or[UNK]f[UNK]BWr?zFbd?[UNK][UNK][UNK]d\\n[UNK]d[UNK]I[UNK]S![UNK]fBO\"\n"]}]},{"cell_type":"code","source":["loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n","example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n","print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n","print(\"Mean loss:        \", example_batch_mean_loss)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sL1GkKBAMvYG","executionInfo":{"status":"ok","timestamp":1687600679914,"user_tz":-330,"elapsed":46,"user":{"displayName":"Madhusudhana","userId":"07612415316378441544"}},"outputId":"ecb476fa-201d-4a32-9e25-15289d14fcac"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Prediction shape:  (64, 100, 66)  # (batch_size, sequence_length, vocab_size)\n","Mean loss:         tf.Tensor(4.189749, shape=(), dtype=float32)\n"]}]},{"cell_type":"code","source":["tf.exp(example_batch_mean_loss).numpy()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oULVS8-YOyXU","executionInfo":{"status":"ok","timestamp":1687600679915,"user_tz":-330,"elapsed":38,"user":{"displayName":"Madhusudhana","userId":"07612415316378441544"}},"outputId":"64c41bf8-d9f3-4f3c-889a-5690a7da7aed"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["66.0062"]},"metadata":{},"execution_count":74}]},{"cell_type":"code","source":["# model.compile(optimizer='adam', loss=loss)"],"metadata":{"id":"v_734XzaOyyJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Directory where the checkpoints will be saved\n","checkpoint_dir = './training_checkpoints'\n","# Name of the checkpoint files\n","import os\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n","\n","checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_prefix,\n","    save_weights_only=True)"],"metadata":{"id":"Y8KWq1UjO1dl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["EPOCHS = 20"],"metadata":{"id":"0oTEy8zwO3nh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CustomTraining(MyModel):\n","  @tf.function\n","  def train_step(self, inputs):\n","      inputs, labels = inputs\n","      with tf.GradientTape() as tape:\n","          predictions = self(inputs, training=True)\n","          loss = self.loss(labels, predictions)\n","      grads = tape.gradient(loss, model.trainable_variables)\n","      self.optimizer.apply_gradients(zip(grads, model.trainable_variables))\n","\n","      return {'loss': loss}\n","\n","model = CustomTraining(\n","    vocab_size=len(ids_from_chars.get_vocabulary()),\n","    embedding_dim=embedding_dim,\n","    rnn_units=rnn_units)"],"metadata":{"id":"KiSdi8UxO--8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(optimizer = tf.keras.optimizers.Adam(),\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))"],"metadata":{"id":"J6bQbUWkPA31"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# model.fit(dataset, epochs=1)"],"metadata":{"id":"bGdJ93gZSiS7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# EPOCHS = 5\n","\n","# mean = tf.metrics.Mean()\n","# import time\n","# for epoch in range(EPOCHS):\n","#     start = time.time()\n","\n","#     mean.reset_states()\n","#     for (batch_n, (inp, target)) in enumerate(dataset):\n","#         logs = model.train_step([inp, target])\n","#         mean.update_state(logs['loss'])\n","\n","#         if batch_n % 50 == 0:\n","#             template = f\"Epoch {epoch+1} Batch {batch_n} Loss {logs['loss']:.4f}\"\n","#             print(template)\n","\n","#     # saving (checkpoint) the model every 5 epochs\n","#     if (epoch + 1) % 5 == 0:\n","#         model.save_weights(checkpoint_prefix.format(epoch=epoch))\n","\n","#     print()\n","#     print(f'Epoch {epoch+1} Loss: {mean.result().numpy():.4f}')\n","#     print(f'Time taken for 1 epoch {time.time() - start:.2f} sec')\n","#     print(\"_\"*80)\n","\n","# model.save_weights(checkpoint_prefix.format(epoch=epoch))"],"metadata":{"id":"DlYm_SRmSksI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_text = [\"Hello\"]\n","test_ids = text_preprocessing(test_text)\n","print(test_ids)\n","pred, state = model(inputs=test_ids, return_state=True)\n","test_op = text_preprocessing(pred, reverse=True)\n","print(test_op)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZIW76Y4JaHiD","executionInfo":{"status":"ok","timestamp":1687600681396,"user_tz":-330,"elapsed":1510,"user":{"displayName":"Madhusudhana","userId":"07612415316378441544"}},"outputId":"99244bf3-88a1-4600-d92d-e027ed39e06a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<tf.RaggedTensor [[0, 27, 34, 34, 37]]>\n","[[b'[UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK]'\n","  b'[UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK]'\n","  b'[UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK]'\n","  b'[UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK]'\n","  b'[UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK][UNK]']]\n"]}]},{"cell_type":"code","source":["# print(tf.random.categorical(pred,  num_samples=1))\n","# print(pred[0])\n","sample_indeces = tf.random.categorical(pred[0], num_samples=1)\n","print(sample_indeces)\n","sample_indeces = tf.squeeze(sample_indeces, axis=-1).numpy()\n","print(sample_indeces)\n","# print(text_preprocessing(input_example_batch[0], reverse=True))\n","print(text_preprocessing(sample_indeces, reverse=True))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BJVZ8S6lxwHZ","executionInfo":{"status":"ok","timestamp":1687600681397,"user_tz":-330,"elapsed":18,"user":{"displayName":"Madhusudhana","userId":"07612415316378441544"}},"outputId":"8bb737e5-a1d5-4fdf-a8ab-5d5f9a5c042d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[[30]\n"," [21]\n"," [15]\n"," [ 0]\n"," [10]], shape=(5, 1), dtype=int64)\n","[30 21 15  0 10]\n","b'hWL[UNK]A'\n"]}]},{"cell_type":"code","source":["for input_example_batch, target_example_batch in dataset.take(1):\n","    print(f\"input_example_batch= {input_example_batch}\")\n","    example_batch_predictions = model(input_example_batch)\n","    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n","    print(f\"example_batch_predictions= {example_batch_predictions}\")"],"metadata":{"id":"VK-xMeMhw5gW"},"execution_count":null,"outputs":[]}]}