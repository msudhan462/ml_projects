{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0948dccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-26 18:18:36.074505: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-26 18:18:36.329623: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-26 18:18:36.340380: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-26 18:18:36.340414: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-11-26 18:18:36.395691: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-26 18:18:37.597155: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-26 18:18:37.597239: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-26 18:18:37.597249: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Mean, SparseCategoricalAccuracy\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132ec3ed",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f56f917",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(train_images, train_labels) , (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images/255.0\n",
    "train_images = train_images[..., tf.newaxis].astype(\"float32\")\n",
    "\n",
    "test_images = test_images/255.0\n",
    "test_images = test_images[..., tf.newaxis].astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2edab589",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-26 18:18:39.883160: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-26 18:18:39.883595: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-26 18:18:39.883675: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-11-26 18:18:39.883740: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-11-26 18:18:39.883800: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-11-26 18:18:39.883863: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-11-26 18:18:39.883924: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-11-26 18:18:39.883993: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-11-26 18:18:39.884048: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-11-26 18:18:39.884061: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-11-26 18:18:39.885421: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "train_ds = train_ds.shuffle(10000).batch(BATCH_SIZE)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
    "test_ds = test_ds.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b522d52e",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb9a5b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassfier(Model):\n",
    "    \n",
    "    def __init__(self,name):\n",
    "        \n",
    "        conv_units = 32\n",
    "        conv_kernal = 3\n",
    "        conv_activation = tf.nn.relu\n",
    "\n",
    "        dense1_units = 128\n",
    "        dense1_activation = tf.nn.relu\n",
    "\n",
    "        dense2_units = 10 # last layer, 10 units for 10 classes\n",
    "        \n",
    "        super(ImageClassfier, self).__init__(name=name)\n",
    "        self.conv2d = Conv2D(filters=conv_units, kernel_size=conv_kernal, activation=conv_activation)\n",
    "        self.flatten = Flatten()\n",
    "        self.dense1 = Dense(units=dense1_units, activation=dense1_activation)\n",
    "        self.dense2 = Dense(units=dense2_units)\n",
    "        \n",
    "    def call(self, images):\n",
    "        \n",
    "        conv_images = self.conv2d(images)\n",
    "        flatten_images = self.flatten(conv_images)\n",
    "        dense1_images = self.dense1(flatten_images)\n",
    "        return self.dense2(dense1_images)\n",
    "    \n",
    "model = ImageClassfier(name='image_claffier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ea64516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one_bacth = train_ds.take(1)\n",
    "# for img, label in one_bacth:\n",
    "#     pred = model(img)\n",
    "#     pred = tf.nn.softmax(pred)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ed6aac",
   "metadata": {},
   "source": [
    "### Optimizer, Loss, Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50fd24ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_obj =  SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = Adam()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1049d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = Mean(name='train_loss')\n",
    "test_loss = Mean(name='test_loss')\n",
    "\n",
    "train_acc = SparseCategoricalAccuracy(name=\"train_acc\")\n",
    "test_acc = SparseCategoricalAccuracy(name=\"test_acc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2646a6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred = model(images, training=True)\n",
    "        loss = loss_obj(labels, pred)\n",
    "        \n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    train_loss(loss)\n",
    "    train_acc(labels, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d724d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "#     with tf.GradientTape() as tape:\n",
    "    pred = model(images, training=False)\n",
    "    loss_t = loss_obj(labels, pred)\n",
    "        \n",
    "#     gradients = tape.gradient(loss, model.trainable_variables)\n",
    "#     optimizer.apply_gradients(gradients, model.trainable_variables)\n",
    "    \n",
    "    test_loss(loss_t)\n",
    "    test_acc(labels, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cf99f0",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed8bff1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|███████▌                                     | 1/6 [00:30<02:30, 30.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.13489685952663422, Accuracy: 95.96499633789062, Test Loss: 0.08001945912837982, Test Accuracy: 97.43000030517578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███████████████                              | 2/6 [00:51<01:38, 24.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.04448465630412102, Accuracy: 98.65499877929688, Test Loss: 0.05787041410803795, Test Accuracy: 98.07999420166016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|██████████████████████▌                      | 3/6 [01:12<01:09, 23.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.022394930943846703, Accuracy: 99.27166748046875, Test Loss: 0.06716636568307877, Test Accuracy: 97.98999786376953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████████████████████████████               | 4/6 [01:33<00:44, 22.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.016739148646593094, Accuracy: 99.4183349609375, Test Loss: 0.05776520445942879, Test Accuracy: 98.29000091552734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|█████████████████████████████████████▌       | 5/6 [01:54<00:21, 21.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.009011219255626202, Accuracy: 99.711669921875, Test Loss: 0.0632745698094368, Test Accuracy: 98.3499984741211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 6/6 [02:15<00:00, 22.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.00832319725304842, Accuracy: 99.7266616821289, Test Loss: 0.061394188553094864, Test Accuracy: 98.29000091552734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(1, EPOCHS+1)):\n",
    "    train_loss.reset_states()\n",
    "    test_loss.reset_states()    \n",
    "    train_acc.reset_states()\n",
    "    test_acc.reset_states()\n",
    "    \n",
    "    for images, labels in train_ds:\n",
    "        train_step(images, labels)\n",
    "    \n",
    "    for t_images, t_labels in test_ds:\n",
    "        test_step(t_images, t_labels)\n",
    "    \n",
    "    print(\n",
    "        f'Epoch {epoch + 1}, '\n",
    "        f'Loss: {train_loss.result()}, '\n",
    "        f'Accuracy: {train_acc.result() * 100}, '\n",
    "        f'Test Loss: {test_loss.result()}, '\n",
    "        f'Test Accuracy: {test_acc.result() * 100}'\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d98559f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"image_claffier\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             multiple                  320       \n",
      "                                                                 \n",
      " flatten (Flatten)           multiple                  0         \n",
      "                                                                 \n",
      " dense (Dense)               multiple                  2769024   \n",
      "                                                                 \n",
      " dense_1 (Dense)             multiple                  1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,770,634\n",
      "Trainable params: 2,770,634\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85f625d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 54ms/step\n",
      "7 tf.Tensor(7, shape=(), dtype=uint8)\n",
      "2 tf.Tensor(2, shape=(), dtype=uint8)\n",
      "1 tf.Tensor(1, shape=(), dtype=uint8)\n",
      "0 tf.Tensor(0, shape=(), dtype=uint8)\n",
      "4 tf.Tensor(4, shape=(), dtype=uint8)\n",
      "1 tf.Tensor(1, shape=(), dtype=uint8)\n",
      "4 tf.Tensor(4, shape=(), dtype=uint8)\n",
      "9 tf.Tensor(9, shape=(), dtype=uint8)\n",
      "5 tf.Tensor(5, shape=(), dtype=uint8)\n",
      "9 tf.Tensor(9, shape=(), dtype=uint8)\n",
      "0 tf.Tensor(0, shape=(), dtype=uint8)\n",
      "6 tf.Tensor(6, shape=(), dtype=uint8)\n",
      "9 tf.Tensor(9, shape=(), dtype=uint8)\n",
      "0 tf.Tensor(0, shape=(), dtype=uint8)\n",
      "1 tf.Tensor(1, shape=(), dtype=uint8)\n",
      "5 tf.Tensor(5, shape=(), dtype=uint8)\n",
      "9 tf.Tensor(9, shape=(), dtype=uint8)\n",
      "7 tf.Tensor(7, shape=(), dtype=uint8)\n",
      "5 tf.Tensor(3, shape=(), dtype=uint8)\n",
      "4 tf.Tensor(4, shape=(), dtype=uint8)\n",
      "9 tf.Tensor(9, shape=(), dtype=uint8)\n",
      "6 tf.Tensor(6, shape=(), dtype=uint8)\n",
      "6 tf.Tensor(6, shape=(), dtype=uint8)\n",
      "5 tf.Tensor(5, shape=(), dtype=uint8)\n",
      "4 tf.Tensor(4, shape=(), dtype=uint8)\n",
      "0 tf.Tensor(0, shape=(), dtype=uint8)\n",
      "7 tf.Tensor(7, shape=(), dtype=uint8)\n",
      "4 tf.Tensor(4, shape=(), dtype=uint8)\n",
      "0 tf.Tensor(0, shape=(), dtype=uint8)\n",
      "1 tf.Tensor(1, shape=(), dtype=uint8)\n",
      "3 tf.Tensor(3, shape=(), dtype=uint8)\n",
      "1 tf.Tensor(1, shape=(), dtype=uint8)\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "import numpy as np\n",
    "for images, labels in test_ds.take(1):\n",
    "    pred = model.predict(images)\n",
    "    for pred, actuals in zip(pred, labels):\n",
    "        print(np.array(pred).argmax(), actuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebd835b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3019149c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
